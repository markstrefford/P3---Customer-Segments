{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Customer Segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project you, will analyze a dataset containing annual spending amounts for internal structure, to understand the variation in the different types of customers that a wholesale distributor interacts with.\n",
    "\n",
    "Instructions:\n",
    "\n",
    "- Run each code block below by pressing **Shift+Enter**, making sure to implement any steps marked with a TODO.\n",
    "- Answer each question in the space provided by editing the blocks labeled \"Answer:\".\n",
    "- When you are done, submit the completed notebook (.ipynb) with all code blocks executed, as well as a .pdf version (File > Download as)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has 440 rows, 6 columns\n",
      "   Fresh  Milk  Grocery  Frozen  Detergents_Paper  Delicatessen\n",
      "0  12669  9656     7561     214              2674          1338\n",
      "1   7057  9810     9568    1762              3293          1776\n",
      "2   6353  8808     7684    2405              3516          7844\n",
      "3  13265  1196     4221    6404               507          1788\n",
      "4  22615  5410     7198    3915              1777          5185\n"
     ]
    }
   ],
   "source": [
    "# Import libraries: NumPy, pandas, matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Tell iPython to include plots inline in the notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# Read dataset\n",
    "data = pd.read_csv(\"wholesale-customers.csv\")\n",
    "print \"Dataset has {} rows, {} columns\".format(*data.shape)\n",
    "print data.head()  # print the first 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Feature Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1)** In this section you will be using PCA and ICA to start to understand the structure of the data. Before doing any computations, what do you think will show up in your computations? List one or two ideas for what might show up as the first PCA dimensions, or what type of vectors will show up as ICA dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: \n",
    "I think that PCA will highlight the products that are sold the most, for example fresh, milk and groceries may be combined into a single (or smaller number of) features.\n",
    "For ICA, I think it may start to find new features that highlight the different customer types earlier on based on their spending patterns. It may identify those that purchase different types of products more often than other types of products.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.97653685 -0.12118407 -0.06154039 -0.15236462  0.00705417 -0.06810471]\n",
      " [-0.11061386  0.51580216  0.76460638 -0.01872345  0.36535076  0.05707921]\n",
      " [-0.17855726  0.50988675 -0.27578088  0.71420037 -0.20440987  0.28321747]\n",
      " [-0.04187648 -0.64564047  0.37546049  0.64629232  0.14938013 -0.02039579]\n",
      " [ 0.015986    0.20323566 -0.1602915   0.22018612  0.20793016 -0.91707659]\n",
      " [-0.01576316  0.03349187  0.41093894 -0.01328898 -0.87128428 -0.26541687]]\n",
      "[ 0.45961362  0.40517227  0.07003008  0.04402344  0.01502212  0.00613848]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Apply PCA with the same number of dimensions as variables in the dataset\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=6).fit(data)\n",
    "\n",
    "# Print the components and the amount of variance in the data contained in each dimension\n",
    "print pca.components_\n",
    "print pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2)** How quickly does the variance drop off by dimension? If you were to use PCA on this dataset, how many dimensions would you choose for your analysis? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Answer: \n",
    "Variance drops off significantly after 2 dimensions, therefore I would choose to use 2 dimensions for my analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3)** What do the dimensions seem to represent? How can you use this information?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Answer: \n",
    "I'd guess that the dimensions represent the relative importance of each of the features, so the first 2 features are the most important in determing which features I would use to train on. After that, it appears that training using the 3rd, 4th, 5th and 6th features will not make much improvement to the accuracy of the algorithm.\n",
    "These 2 dimensions will likely give an indication of the type of customer, so which is a larger customer and which is a smaller customer.\n",
    "\n",
    "The vectors above represent how each of the principle components identified correlate to the features in the dataset.  From my testing, these values were determed for the 2 dimensions identified above:\n",
    "\n",
    "Dimension 1:\n",
    "[-0.97653685 -0.12118407 -0.06154039 -0.15236462  0.00705417 -0.06810471]\n",
    "This shows that the this principle component (PC1) is most heavily correlated with fresh food, and in particular this is a negative correlation reflecting that this is related to not selling as much fresh food.  The 2nd correlation is with milk, and again this relates to not selling as much milk. \n",
    "\n",
    "Dimension 2:\n",
    "[-0.11061386  0.51580216  0.76460638 -0.01872345  0.36535076  0.05707921]\n",
    "This dimension shows that it correlates most significantly with selling grocery, milk and detergents/paper.  It also has a negative correlation with fresh."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###ICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Fresh      Milk   Grocery    Frozen  Detergents_Paper  Delicatessen\n",
      "0 -0.010884 -0.001081  0.007352  0.054062         -0.002547     -0.016882\n",
      "1 -0.002023 -0.072265  0.056706  0.001636         -0.017840      0.016877\n",
      "2 -0.002482  0.012466 -0.071079 -0.001292          0.015845      0.005594\n",
      "3  0.004932  0.001578  0.005578  0.002395         -0.002397     -0.050898\n",
      "4  0.003286 -0.019221 -0.107596  0.007268          0.133039      0.016032\n",
      "5  0.050274 -0.006585 -0.007647 -0.003219          0.011731     -0.002652\n"
     ]
    }
   ],
   "source": [
    "# TODO: Fit an ICA model to the data\n",
    "# Note: Adjust the data to have center at the origin first!\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn import preprocessing\n",
    "data_centered = preprocessing.scale(data)\n",
    "#ica = FastICA().fit(data_centered)\n",
    "ica = FastICA(n_components = data.shape[1], random_state = 3).fit(data_centered)\n",
    "df = pd.DataFrame(ica.components_, columns = data.columns)\n",
    "\n",
    "# Print the independent components\n",
    "print df\n",
    "#print ica.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4)** For each vector in the ICA decomposition, write a sentence or two explaining what sort of object or property it corresponds to. What could these components be used for?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Answer:\n",
    "Each vector relates to how each feature in the data set contributes to the original sources (so the customer segments) that created this data. These components can be used to start to determine the different customer segments. The default settings assume that there are the same number of sources (components) as features and therefore the matrix can be used to group the customers into 6 types based on their propensity to purchase the different types of products.\n",
    "\n",
    "Using this data, we can see that:\n",
    "\n",
    "Source 0: [-0.010884 -0.001081  0.007352  0.054062  -0.002547  -0.016882]\n",
    "This source is related to selling more grocery and frozen and less fresh, milk, detergents/paper and delicatessen. Frozen is the most important in this source.\n",
    "\n",
    "Source 1: [1 -0.002023 -0.072265  0.056706  0.001636         -0.017840      0.016877]\n",
    "This source is related to selling more grocery, frozen and delicatessen, and less milk. Milk and grocery are the highest importance in this source.\n",
    "\n",
    "Source 2: [-0.002482  0.012466 -0.071079 -0.001292          0.015845      0.005594]\n",
    "This source is related to selling more milk, detergents/paper and delicatessen. However the biggest influence relates to less grocery.\n",
    "\n",
    "Source 3: [0.004932  0.001578  0.005578  0.002395         -0.002397     -0.050898]\n",
    "This source is related to selling more fresh, milk, grocery and frozen.  Fresh and grocery are the most important products in this source.\n",
    "\n",
    "Source 4: [0.003286 -0.019221 -0.107596  0.007268          0.133039      0.016032]\n",
    "This source is related to not selling milk or grocey, but selling fresh and detergents/paper.  Detergents/paper and grocery are the most important here.\n",
    "\n",
    "Source 5: [0.050274 -0.006585 -0.007647 -0.003219          0.011731     -0.002652]\n",
    "This source relates to slling fresh (primarily) and detergents/paper. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Clustering\n",
    "\n",
    "In this section you will choose either K Means clustering or Gaussian Mixed Models clustering, which implements expectation-maximization. Then you will sample elements from the clusters to understand their significance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Choose a Cluster Type\n",
    "\n",
    "**5)** What are the advantages of using K Means clustering or Gaussian Mixture Models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: \n",
    "\n",
    "K Means clustering works if the number of clusters in the data is already known.  It also scales well to large numbers of samples and has been demonstrated to work in many different fields.  Because of the known number of clusters, K Means is often very fast in determining which sample is in which cluster.\n",
    "\n",
    "Gaussian Mixture Models typically identity the dominant patterns well.  They also have well-studied statistical inference models available, and it's also possible to determine the density of each cluster. These models also can determine the covariance of different features in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6)** Below is some starter code to help you visualize some cluster data. The visualization is based on [this demo](http://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_digits.html) from the sklearn documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import clustering modules\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  -650.02212207   1585.51909007]\n",
      " [  4426.80497937   4042.45150884]\n",
      " [  4841.9987068    2578.762176  ]\n",
      " [  -990.34643689  -6279.80599663]\n",
      " [-10657.99873116  -2159.72581518]\n",
      " [  2765.96159271   -959.87072713]\n",
      " [   715.55089221  -2013.00226567]\n",
      " [  4474.58366697   1429.49697204]\n",
      " [  6712.09539718  -2205.90915598]\n",
      " [  4823.63435407  13480.55920489]]\n"
     ]
    }
   ],
   "source": [
    "# TODO: First we reduce the data to two dimensions using PCA to capture variation\n",
    "reduced_data = PCA(n_components = 2).fit(data).transform(data)\n",
    "print reduced_data[:10]  # print upto 10 elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans(copy_x=True, init='k-means++', max_iter=300, n_clusters=2, n_init=10,\n",
      "    n_jobs=1, precompute_distances='auto', random_state=None, tol=0.0001,\n",
      "    verbose=0)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement your clustering algorithm here, and fit it to the reduced data for visualization\n",
    "# The visualizer below assumes your clustering object is named 'clusters'\n",
    "\n",
    "clusters = KMeans(n_clusters=2).fit(reduced_data)\n",
    "print clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the decision boundary by building a mesh grid to populate a graph.\n",
    "x_min, x_max = reduced_data[:, 0].min() - 1, reduced_data[:, 0].max() + 1\n",
    "y_min, y_max = reduced_data[:, 1].min() - 1, reduced_data[:, 1].max() + 1\n",
    "hx = (x_max-x_min)/1000.\n",
    "hy = (y_max-y_min)/1000.\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, hx), np.arange(y_min, y_max, hy))\n",
    "\n",
    "# Obtain labels for each point in mesh. Use last trained model.\n",
    "Z = clusters.predict(np.c_[xx.ravel(), yy.ravel()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  4175.31101293   -211.15109304]\n",
      " [-24088.33276689   1218.17938291]]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Find the centroids for KMeans or the cluster means for GMM \n",
    "\n",
    "centroids = clusters.cluster_centers_\n",
    "print centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAELCAYAAAAY3LtyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115268690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Put the result into a color plot\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(1)\n",
    "plt.clf()\n",
    "plt.imshow(Z, interpolation='nearest',\n",
    "           extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
    "           cmap=plt.cm.Paired,\n",
    "           aspect='auto', origin='lower')\n",
    "\n",
    "plt.plot(reduced_data[:, 0], reduced_data[:, 1], 'k.', markersize=2)\n",
    "plt.scatter(centroids[:, 0], centroids[:, 1],\n",
    "            marker='x', s=169, linewidths=3,\n",
    "            color='w', zorder=10)\n",
    "plt.title('Clustering on the wholesale grocery dataset (PCA-reduced data)\\n'\n",
    "          'Centroids are marked with white cross')\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7)** What are the central objects in each cluster? Describe them as customers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Answer: The central objects in each cluster are the means for each customer in the cluster.  For example, if we assume that the 2 clusters are \"large\" and \"small\" customers of the wholesaler, then each of the central objects is the mean of all of those types of customers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Conclusions\n",
    "\n",
    "** 8)** Which of these techniques did you feel gave you the most insight into the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Answer: \n",
    "As a business owner, I would look to use a mix of all 3 techniques.\n",
    "\n",
    "initially use the KMeans clustering algorithm to give me the best insights into the data.  This is because I can clearly see the different clusters I have and how they relate to my individual customers. \n",
    "\n",
    "In the future, I may start to use PCA to determine which are the most influential product categories between these 2 groups. I could also look to use ICA to determine if there were a deeper level of information that is not immediately evident in this data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**9)** How would you use that technique to help the company design new experiments?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: \n",
    "I would start to run experiments on each type of customer, for example using the most influential product categories first and seeing how changes in either would change the amount of product sold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10)** How would you use that data to help you predict future customer needs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: \n",
    "Effectively I would look for changes in the data over time (trends).  Examples could be:\n",
    "- I could look at whether any customers started to move towards the boundary between the segments, as this may suggest they are growing (or not!).\n",
    "- I could also look at whether the mix of products changes, so for example whether another category starts to gain traction with a set of customers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
